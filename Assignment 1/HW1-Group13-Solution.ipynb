{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Submission for Group 13\n",
    "## Members: Archit Patel, Prakhar Bansal, Vishal Gupta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rps(choice, counter, user_dict):\n",
    "    '''\n",
    "    This function takes input from user r/p/s correspondnig to Rock, Paper and Scissors. It passes the value corresponding to\n",
    "    the input choice (e.g.1 for r, 2 for p and 3 for s) as an argument to the winner function.\n",
    "      \n",
    "    Input: It takes user choice as input (r/p/s is taken as input  \n",
    "    Output: returns the value corresponding the the choice key as an input to another function winner()\n",
    "    '''\n",
    "    choice_dict = {'r': 1, 'p': 2, 's': 3}\n",
    "    return winner(choice_dict[choice], counter, user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(y, counter, user_dict):\n",
    "    '''\n",
    "    This function takes input value corresponding to the user input and prints the individual game results after comparing\n",
    "    the user and computer responses. The logic for computer response has been formulated here.\n",
    "      \n",
    "    Input: It takes value corresponding to the choice as input  \n",
    "    Output: prints the game result and returns the outcome.\n",
    "    '''\n",
    "    rps_dict = {1: 'rock', 2: 'paper', 3: 'scissor'}\n",
    "    winner_dict = {1:2, 2:3, 3:1} #storing the computer response against value corresponding to user input; for user \n",
    "                                  #input as r (value = 1), computer would chose p (value = 2) as rock smashes scissors\n",
    "    rps_list = [1,2,3]\n",
    "\n",
    "    #start with a random choice\n",
    "    if counter == 0:\n",
    "        x = random.choice(rps_list) #first response of the computer will be random\n",
    "    else:\n",
    "        max_count = max(user_dict.values())\n",
    "\n",
    "        user_likely = []\n",
    "        for key in user_dict.keys():\n",
    "          if user_dict[key] == max_count:\n",
    "            user_likely.append(key)\n",
    "\n",
    "        x = random.choice(user_likely)\n",
    "        x = winner_dict[x]\n",
    "\n",
    "    user_dict[y] += 1\n",
    "   \n",
    "    if x == y:\n",
    "        print('\\nComputer chose {}, its a tie!'.format(rps_dict[x]))\n",
    "        winner_name = 'tie'\n",
    "    elif x == winner_dict[y]:\n",
    "        print('\\nComputer chose {}, you lose!'.format(rps_dict[x]))\n",
    "        winner_name = 'computer'\n",
    "    else:\n",
    "        print('\\nComputer chose {}, you win!'.format(rps_dict[x]))\n",
    "        winner_name = 'user'\n",
    "\n",
    "    outcome[winner_name] += 1\n",
    "\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter \"r\" for rock, \"p\" for paper, or \"s\" for scissors.\n",
      "Please enter q to quit, if you are done playing  \n",
      "\n",
      "That is not a valid input, try again.\n",
      "\n",
      "Enter \"r\" for rock, \"p\" for paper, or \"s\" for scissors.\n",
      "Please enter q to quit, if you are done playing  \n",
      "\n",
      "That is not a valid input, try again.\n",
      "\n",
      "Enter \"r\" for rock, \"p\" for paper, or \"s\" for scissors.\n",
      "Please enter q to quit, if you are done playing  s\n",
      "\n",
      "Computer chose scissor, its a tie!\n",
      "\n",
      "Enter \"r\" for rock, \"p\" for paper, or \"s\" for scissors.\n",
      "Please enter q to quit, if you are done playing  p\n",
      "\n",
      "Computer chose rock, you win!\n",
      "\n",
      "Enter \"r\" for rock, \"p\" for paper, or \"s\" for scissors.\n",
      "Please enter q to quit, if you are done playing  s\n",
      "\n",
      "Computer chose scissor, its a tie!\n",
      "\n",
      "Enter \"r\" for rock, \"p\" for paper, or \"s\" for scissors.\n",
      "Please enter q to quit, if you are done playing  q\n",
      "\n",
      "You have played the game 3 times.\n",
      "You won 1 times.\n",
      "Computer won 0 times.\n",
      "You and the computer tied 2 times.\n",
      "\n",
      "Your winning percentage was 33 % \n",
      "You need to work on :P\n"
     ]
    }
   ],
   "source": [
    "#Run function\n",
    "#Keeps the count of number of times the game has been played\n",
    "counter = 0 \n",
    "\n",
    "# initializing variables\n",
    "user_dict = {1:0, 2:0, 3:0}\n",
    "\n",
    "outcome = {'user':0, 'computer':0, 'tie':0}\n",
    "\n",
    "while True:\n",
    "\n",
    "    userwinner = outcome['user'] #To count number of times, the user wins\n",
    "    compwinner = outcome['computer'] #To count number of times, the computer wins\n",
    "    tie = outcome['tie'] #To count number of times there is a tie\n",
    "    choice = input('\\nEnter \"r\" for rock, \"p\" for paper, or \"s\" for scissors.\\nPlease enter q to quit, if you are done playing  ')\n",
    "    if choice == 'q':\n",
    "        if counter == 0:\n",
    "            print('You haven\"t played rock paper scissor')\n",
    "        else:\n",
    "            print('\\nYou have played the game', counter, 'times.')\n",
    "            print('You won', userwinner, 'times.')\n",
    "            print('Computer won', compwinner, 'times.')\n",
    "            print('You and the computer tied', tie, 'times.') \n",
    "            if userwinner/float(counter) >= .8:\n",
    "                print('Your winning percentage was',int(round(userwinner/float(counter),2)*100),'%','\\nYou seem to be a professional :)' )\n",
    "            elif userwinner/float(counter) >= .4:\n",
    "                print('Your winning percentage was',int(round(userwinner/float(counter),2)*100),'%','\\nNo Bad')\n",
    "            if userwinner/float(counter) < .4:\n",
    "                print('\\nYour winning percentage was',int(round(userwinner/float(counter),2)*100),'%','\\nYou need to work on :P')\n",
    "        break\n",
    "    elif choice in ['r', 'p', 's']:\n",
    "        outcome = rps(choice, counter, user_dict)\n",
    "        counter += 1\n",
    "    else:\n",
    "        print('\\nThat is not a valid input, try again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def florida_voters(lines):\n",
    "    '''\n",
    "    Gives the list of counties in florida with Republican and Democratic voters in the given order:\n",
    "    county_name total_republican_voters total_democratic_voters\n",
    "    the list is sorted in ascending order by the number of democratic voters in that county\n",
    "    \n",
    "    Function reads an html file and extracts the contents of the table using regular expressions\n",
    "    \n",
    "    Input: HTML file\n",
    "    Output: Counties with repblican and democratic voters, sorted in ascending order by democratic voters\n",
    "    '''\n",
    "\n",
    "    final_table = []\n",
    "    county = []\n",
    "    for line in lines:\n",
    "        if re.findall('<td>([a-zA-Z]+)</td>',line):\n",
    "            counter = 1\n",
    "            county.append(re.findall('<td>([a-zA-Z]+)</td>',line))\n",
    "            continue\n",
    "        elif re.findall('<td>([\\d,]+)</td>',line):\n",
    "            counter+= 1\n",
    "            if counter<4 :\n",
    "                county.extend(re.findall('<td>([\\d,]+)</td>',line))\n",
    "\n",
    "    county = [x for x in county if len(x)>0]\n",
    "    county = [(county[i][0], int(re.sub(',','',county[i+1])), int(re.sub(',','',county[i+2]))) for i in range(0, len(county), 3)]\n",
    "    sorted_county = sorted(county, key = lambda x: x[2])\n",
    "\n",
    "    for ls in sorted_county:\n",
    "        print(ls[0], ls[1], ls[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAFAYETTE 1373 2672\n",
      "GLADES 2190 3110\n",
      "LIBERTY 720 3372\n",
      "UNION 2752 3579\n",
      "GILCHRIST 5789 3652\n",
      "FRANKLIN 2234 4319\n",
      "HOLMES 5282 4434\n",
      "GULF 4234 4521\n",
      "HARDEE 4859 4702\n",
      "HAMILTON 2154 4796\n",
      "DIXIE 3314 4839\n",
      "CALHOUN 2201 5324\n",
      "WASHINGTON 7101 5687\n",
      "JEFFERSON 2636 5802\n",
      "BAKER 6963 5813\n",
      "BRADFORD 6878 6533\n",
      "TAYLOR 3950 6915\n",
      "MADISON 2992 7158\n",
      "DESOTO 4870 7181\n",
      "OKEECHOBEE 7755 7756\n",
      "HENDRY 5862 7999\n",
      "WAKULLA 7374 8889\n",
      "LEVY 11665 9509\n",
      "WALTON 25609 10013\n",
      "SUWANNEE 10745 11126\n",
      "NASSAU 32958 14013\n",
      "COLUMBIA 15790 14797\n",
      "JACKSON 9626 15706\n",
      "MONROE 20602 17614\n",
      "HIGHLANDS 27100 19997\n",
      "PUTNAM 17067 20606\n",
      "GADSDEN 4372 22161\n",
      "SUMTER 47158 22977\n",
      "FLAGLER 30047 24734\n",
      "OKALOOSA 75154 25172\n",
      "MARTIN 53800 27358\n",
      "CITRUS 46373 30440\n",
      "BAY 57456 30733\n",
      "CLAY 76584 31285\n",
      "CHARLOTTE 54421 35602\n",
      "HERNANDO 51254 42499\n",
      "COLLIER 100167 45511\n",
      "LAKE 93604 67237\n",
      "MANATEE 96063 67926\n",
      "ESCAMBIA 90265 70180\n",
      "OSCEOLA 44594 75657\n",
      "MARION 97306 76268\n",
      "ALACHUA 47329 77996\n",
      "SARASOTA 125872 89711\n",
      "SEMINOLE 107833 91686\n",
      "LEON 54554 103140\n",
      "PASCO 125305 104324\n",
      "LEE 180718 114633\n",
      "VOLUSIA 121402 124136\n",
      "BREVARD 167129 127435\n",
      "POLK 140619 143799\n",
      "PINELLAS 223077 221968\n",
      "DUVAL 210195 229501\n",
      "ORANGE 206174 303458\n",
      "HILLSBOROUGH 257436 314265\n",
      "BROWARD 249762 566185\n",
      "Total 4377713 4637026\n"
     ]
    }
   ],
   "source": [
    "fp = open('FloridaVoters.html','r')\n",
    "lines = fp.readlines()\n",
    "\n",
    "florida_voters(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_window(tweet):\n",
    "    '''\n",
    "    Given a tweet, returns a dictionary with three consecutive words as key and 1 as value\n",
    "    \n",
    "    Input: string - tweet\n",
    "    Output: dictionary, with key as phrase and value as 1\n",
    "    '''\n",
    "    output = {}\n",
    "    \n",
    "    phrase_list = list(tweet.split())\n",
    "    \n",
    "    for i in range(len(phrase_list)-2):\n",
    "        phrase_key = ' '.join(phrase_list[i:i+3])\n",
    "        output[phrase_key] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(tweet1_dict, tweet2_dict):\n",
    "    '''\n",
    "    Give two dictionaries, each containing the 3-word phrases from a tweet. \n",
    "    Return the cosine similarity between the phrases in the two dictionaries\n",
    "    \n",
    "    Input: two dict - tweet phrases\n",
    "    Output: float - cosine similarity\n",
    "    '''\n",
    "    # to calculate cosine similarity\n",
    "    tweet1_phrase = list(tweet1_dict.keys())\n",
    "    tweet2_phrase = list(tweet2_dict.keys())\n",
    "    \n",
    "    n1 = len(tweet1_phrase)\n",
    "    n2 = len(tweet2_phrase)\n",
    "    matches = 0 \n",
    "    \n",
    "    for i in range(len(tweet1_phrase)):\n",
    "        # matching each phrase in tweet1 on tweet 2\n",
    "        if tweet1_phrase[i] in tweet2_phrase:\n",
    "            matches += 1\n",
    "    \n",
    "    cosine_similarity = matches/math.sqrt(n1*n2)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(threshold=0.5):\n",
    "    '''\n",
    "    For each tweet in Santa.txt, calculate cosine similarity with each tweet in the list\n",
    "    and return near duplicate tweets i.e having cosine similarity > 0.5\n",
    "    \n",
    "    Input: threshold for calling near duplicates (optional)\n",
    "    Output: list of list, with each list having - two tweets whcih are near duplicate and their cosine similarity\n",
    "    '''\n",
    "    # Opening the file\n",
    "    fp = open('Santa.txt', 'r')\n",
    "\n",
    "    # initialising tweet phrases dict and tweet list\n",
    "    tweet_dict = {}\n",
    "    tweet_list = []\n",
    "    i=0\n",
    "    \n",
    "    # iteration over each line to get phrase dict per tweet\n",
    "    for line in fp:  \n",
    "        line = line.rstrip().lstrip()\n",
    "        i += 1\n",
    "        tweet_dict['tweet' + str(i)] = moving_window(line)\n",
    "        tweet_list = tweet_list + [line]\n",
    "    \n",
    "    near_duplicate_tweets = []\n",
    "    \n",
    "    # calculating cosine similarity of each tweet with another\n",
    "    for i in range(len(tweet_list)):\n",
    "        tweet1 = tweet_list[i]\n",
    "        tweet1_phrase = tweet_dict['tweet' + str(i+1)]\n",
    "        \n",
    "        for j in range(i+1, len(tweet_list)):\n",
    "            tweet2 = tweet_list[j]\n",
    "            tweet2_phrase = tweet_dict['tweet' + str(j+1)]\n",
    "            cosine_similarity = cosine(tweet1_phrase, tweet2_phrase)\n",
    "            \n",
    "            if cosine_similarity > threshold:\n",
    "                near_duplicate_tweets.append([tweet1, tweet2, cosine_similarity])\n",
    "    \n",
    "    return near_duplicate_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"SPECIAL SECRET HEARTS: A Child's Introduction to Dementia and Pink Curls - A Santa ... - http://t.co/UWCdc8FA9a http://t.co/meexKLGTKl\",\n",
       "  \"RT @BuyBookstore: SPECIAL SECRET HEARTS: A Child's Introduction to Dementia and Pink Curls - A Santa ... - http://t.co/UWCdc8FA9a http://t.\",\n",
       "  0.8838834764831844],\n",
       " ['\"Santa Claus Is Coming To Town #MTVHottest Justin Bieber\"',\n",
       "  '\"RT @DrewFtDevonne_: Rt si te gusta Santa Claus Is Coming To Town #MTVHottest Justin Bieber\"',\n",
       "  0.628970902033151],\n",
       " ['\"Santa Claus Is Coming To Town #MTVHottest Justin Bieber\"',\n",
       "  '\"Rt si te gusta Santa Claus Is Coming To Town #MTVHottest Justin Bieber\"',\n",
       "  0.6837634587578276],\n",
       " ['\"RT @DrewFtDevonne_: Rt si te gusta Santa Claus Is Coming To Town #MTVHottest Justin Bieber\"',\n",
       "  '\"Rt si te gusta Santa Claus Is Coming To Town #MTVHottest Justin Bieber\"',\n",
       "  0.8362420100070908]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a - quote list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_quote_list(lines):\n",
    "    '''\n",
    "    Creates a list of all quotes and joins it with their author\n",
    "    \n",
    "    Input: HTML text\n",
    "    Output: List of quotes and their author\n",
    "    '''\n",
    "    quote = []\n",
    "    author = []\n",
    "    counter = 1\n",
    "\n",
    "    for line in lines:\n",
    "        if counter%2 != 0 :\n",
    "            quote.append(line.strip())\n",
    "            counter+=1\n",
    "            continue\n",
    "        else:\n",
    "            author.append(line.strip())\n",
    "            counter+=1\n",
    "            continue\n",
    "    \n",
    "    quote_list = [quote[i]+' - '+author[i] for i in range(0, len(quote))]\n",
    "    \n",
    "    return quote_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('quotes.txt','r')\n",
    "lines = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quote_list = creating_quote_list(lines)\n",
    "print(quote_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b - word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_list(quote):\n",
    "    '''\n",
    "    The function takes one quote as an input and outputs all the words split by 'alphanumeric_' pattern.\n",
    "    \n",
    "    Input: A single quote\n",
    "    Output: A list of words split by a pattern\n",
    "    '''\n",
    "    quote = quote.lower()\n",
    "    x1 = re.split('\\W+', quote.rstrip())\n",
    "\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_word_list = []\n",
    "for quote in quote_list:\n",
    "    quote_word_list.append(create_word_list(quote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c - posting list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_posting_list(quote_list):\n",
    "    '''\n",
    "    The function creates a dictionary with quotes as keys and a dictionary of values with count of each unique word in it\n",
    "    \n",
    "    Input: List of all the quotes\n",
    "    Output: A dictionary\n",
    "    '''\n",
    "    posting_list_dict = {}\n",
    "    \n",
    "    for quote in quote_list:\n",
    "        word_list = create_word_list(quote)\n",
    "        posting_list_dict[quote] = {}    \n",
    "\n",
    "        for s in word_list:\n",
    "            if s in posting_list_dict[quote].keys():\n",
    "                posting_list_dict[quote][s] += 1\n",
    "            else:\n",
    "                posting_list_dict[quote][s] = 1\n",
    "    \n",
    "    return posting_list_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posting_list = create_posting_list(quote_list)\n",
    "posting_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d reverse posting list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reverse_posting_list(posting_list):\n",
    "    '''\n",
    "    The function creates a dictionary with keys as all the unique words in the quote list and a dictionary of values with count of each quote in which the word(key) appears\n",
    "    \n",
    "    Input: Dictionary created in the create_posting_list function\n",
    "    Output: A dictionary\n",
    "    '''\n",
    "    reverse_posting_list = {}\n",
    "    \n",
    "    # get list of unique keys for reverse list\n",
    "    word_dict_list = list(posting_list.values())\n",
    "    doc_word_list = []\n",
    "    for s in word_dict_list:\n",
    "        s_keys_list = list(s.keys())\n",
    "        doc_word_list += s_keys_list\n",
    "\n",
    "    # using set to get unique list of words\n",
    "    doc_word_list = list(set(doc_word_list))\n",
    "    \n",
    "    # scanning each word through each quote in posting list\n",
    "    for word in doc_word_list:\n",
    "        reverse_posting_list[word] = {}\n",
    "        for quote in posting_list.keys():\n",
    "            if word in posting_list[quote].keys():\n",
    "                reverse_posting_list[word][quote] = posting_list[quote][word]\n",
    "    \n",
    "    return reverse_posting_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_posting_list = create_reverse_posting_list(posting_list)\n",
    "reverse_posting_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part e  tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tf(word, quote, posting_list):\n",
    "    '''\n",
    "    Returns a Term Frequency score of total no of times a word occurs in a quote divided by the maximum no of times any word occurs in that quote.\n",
    "    \n",
    "    Input: (Word, Quote, posting_list dictionary created in create_posting_list function)\n",
    "    Output: Term Frequency Score\n",
    "    '''\n",
    "    if word in posting_list[quote].keys():\n",
    "        word_freq = posting_list[quote][word]\n",
    "        max_freq = max(posting_list[quote].values())\n",
    "\n",
    "        return word_freq/float(max_freq)\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "print(quote_list[6])\n",
    "calc_tf('blaise', quote_list[6], posting_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_idf(word, quote_list, reverse_posting_list):\n",
    "\n",
    "    '''\n",
    "    Returns an Inverse Document Frequency score which is total number of quotes divided by the number of quotes containing a particular word.\n",
    "    \n",
    "    Input: Word, Quote_List, Reverse_posting_list dictionary create in the create_reverse_posting_list\n",
    "    Output: Returns IDF score \n",
    "    '''\n",
    "    return math.log(len(quote_list)/len(reverse_posting_list[word].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "calc_idf('blaise', quote_list, reverse_posting_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(word, quote, posting_list, reverse_posting_list, quote_list):\n",
    "    '''\n",
    "    Calculates TF-IDF score by multiplyng tf*idf scores\n",
    "    \n",
    "    Input: word, quote, posting_list dictionary, reverse_posting_list dictionary, quote_list\n",
    "    Output: tf-idf score\n",
    "    '''\n",
    "    if word in reverse_posting_list.keys():\n",
    "        tf = calc_tf(word, quote, posting_list)\n",
    "        idf = calc_idf(word, quote_list, reverse_posting_list)\n",
    "        tf_idf = tf * idf\n",
    "        return tf_idf\n",
    "    \n",
    "    else:\n",
    "        print('word not found in any quote')\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "tf_idf('blaise', quote_list[6], posting_list, reverse_posting_list, quote_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_word_quote_search(word):\n",
    "    '''\n",
    "    Returns a dictionary which has keys as quotes which the word passed as argument and tf-idf scores of all those quotes as values\n",
    "    \n",
    "    \n",
    "    Input: word\n",
    "    Ouput: A dictionary\n",
    "    '''\n",
    "    # getting quote list\n",
    "    quote_list = create_quote_list()\n",
    "    \n",
    "    # create posting list\n",
    "    posting_list = create_posting_list(quote_list)\n",
    "\n",
    "    # create reverse posting list\n",
    "    reverse_posting_list = create_reverse_posting_list(posting_list)\n",
    "    \n",
    "    output_dict = {}\n",
    "    for quote in reverse_posting_list[word].keys():\n",
    "        tf_idf_val = tf_idf(word, quote, posting_list, reverse_posting_list, quote_list)\n",
    "        output_dict[quote] = tf_idf_val\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "single_word_quote_search('blaise')\n",
    "\n",
    "# question - should we take word as it is, or it should be made lower??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_word_quote_search(word_list):\n",
    "    '''\n",
    "    Returns a dictionary which has keys as quotes that contain one or more of thrd in word list (word_list passed as an argument).\n",
    "    The values of the dictionary is the sum of all tf-idf scores of words occuring in that quote\n",
    "    \n",
    "    Input: word list\n",
    "    Output: A dictionary\n",
    "    '''\n",
    "    # getting quote list\n",
    "    quote_list = create_quote_list()\n",
    "    \n",
    "    # create posting list\n",
    "    posting_list = create_posting_list(quote_list)\n",
    "\n",
    "    # create reverse posting list\n",
    "    reverse_posting_list = create_reverse_posting_list(posting_list)\n",
    "    \n",
    "    # create quote list \n",
    "    quote_list = []\n",
    "    for word in word_list:\n",
    "        quote_list += list(reverse_posting_list[word].keys())\n",
    "\n",
    "    # getting unique quotes\n",
    "    quote_list = list(set(quote_list))\n",
    "    \n",
    "    output_dict = {}\n",
    "    for quote in quote_list:\n",
    "        output_dict[quote] = 0\n",
    "        for word in word_list:\n",
    "            tf_idf_val = tf_idf(word, quote, posting_list, reverse_posting_list, quote_list)\n",
    "            output_dict[quote] += tf_idf_val\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "multiple_word_quote_search(['blaise', 'annie', 'the'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
